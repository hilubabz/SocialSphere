{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af94e0f7",
   "metadata": {},
   "source": [
    "# 1.Loading Dataset And Data manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "73dc4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e436a5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_file_path='offensive.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14ea925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(csv_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90b0fd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " 10 rows of dataset\n",
      "                                              tweet          class\n",
      "0                              prayer brings peace!  not_offensive\n",
      "1                 You’re a subhuman piece of filth!      offensive\n",
      "2  i respect your opinion, though i don’t share it!  not_offensive\n",
      "3           i’ll make you wish you were never born.      offensive\n",
      "4                      god’s love is unconditional!  not_offensive\n"
     ]
    }
   ],
   "source": [
    "print('\\n 10 rows of dataset')\n",
    "print(df.head(5))#returns first five rows of datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00f6c892",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6942 entries, 0 to 6941\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   tweet   6942 non-null   object\n",
      " 1   class   6940 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 108.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()#returns the info of datset its total no index and columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a87887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tweet', 'class']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.to_list())#name of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72d12caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class\n",
      "offensive         4113\n",
      "not_offensive     2823\n",
      " not_offensive       3\n",
      "label                1\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Loaded 6942 blog contents and 6942 labels.\n"
     ]
    }
   ],
   "source": [
    "content_label='tweet'\n",
    "category_label='class'\n",
    "\n",
    "print(df[category_label].value_counts())\n",
    "\n",
    "blog_contents = df[content_label].tolist()\n",
    "blog_category = df[category_label].tolist()\n",
    "\n",
    "print(f\"\\nLoaded {len(blog_contents)} tweets and {len(blog_category)} labels.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c96e3f1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of missing values per column:\n",
      "tweet    0\n",
      "class    2\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "missing_values_count = df.isnull().sum()#checks the empty column\n",
    "print(\"\\nNumber of missing values per column:\")\n",
    "print(missing_values_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b7e1c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of the dataframe before dropping missing values (6942, 2)\n",
      "tweet    0\n",
      "class    0\n",
      "dtype: int64\n",
      "Shape of the dataframe after dropping missing values (6940, 2)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of the dataframe before dropping missing values', df.shape)\n",
    "#removes the missing values NaN or null\n",
    "# df_subset will only drop rows where 'A' column has a NaN value,inplace=True, the operation modifies the original DataFrame directly instead of returning a new one.\n",
    "df.dropna(subset=['tweet'], inplace=True)\n",
    "df.dropna(subset=['class'], inplace=True)\n",
    "values_after = df.isnull().sum()\n",
    "print(values_after)\n",
    "print('Shape of the dataframe after dropping missing values', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "338d2371",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method DataFrame.info of                                                  tweet          class\n",
      "0                                 prayer brings peace!  not_offensive\n",
      "1                    You’re a subhuman piece of filth!      offensive\n",
      "2     i respect your opinion, though i don’t share it!  not_offensive\n",
      "3              i’ll make you wish you were never born.      offensive\n",
      "4                         god’s love is unconditional!  not_offensive\n",
      "...                                                ...            ...\n",
      "6937      I have no strong negative feelings about you  not_offensive\n",
      "6938                                I'm not your enemy  not_offensive\n",
      "6939           I don't feel any resentment towards you  not_offensive\n",
      "6940        My emotions aren't those of hatred for you  not_offensive\n",
      "6941              I'm not holding anything against you  not_offensive\n",
      "\n",
      "[6940 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(df.info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7de86952",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                prayer brings peace!\n",
      "1                   You’re a subhuman piece of filth!\n",
      "2    i respect your opinion, though i don’t share it!\n",
      "3             i’ll make you wish you were never born.\n",
      "4                        god’s love is unconditional!\n",
      "5             People like you should be exterminated!\n",
      "6                 you’re a vile, disgusting creature.\n",
      "7                        god’s love is unconditional.\n",
      "8                                I’ll ruin your life.\n",
      "9    I’m not a fan, but I understand why you like it!\n",
      "Name: tweet, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df['tweet'].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3606bf74",
   "metadata": {},
   "source": [
    "### Test Train Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e34922",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 5552 documents\n",
      "Testing set size: 1388 documents\n"
     ]
    }
   ],
   "source": [
    "\n",
    "random_state=42\n",
    "test_size=0.2\n",
    "\n",
    "df_shuffled = df.sample(frac=1, random_state=random_state).reset_index(drop=True)\n",
    "    \n",
    "split_idx = int(len(df_shuffled) * (1 - test_size))\n",
    "    \n",
    "train_df = df_shuffled.iloc[:split_idx]\n",
    "test_df = df_shuffled.iloc[split_idx:]\n",
    "\n",
    "X_train_raw = train_df['tweet'].tolist()\n",
    "y_train_str = train_df['class'].tolist()\n",
    "X_test_raw = test_df['tweet'].tolist()\n",
    "y_test_str = test_df['class'].tolist()\n",
    "\n",
    "print(f\"Training set size: {len(X_train_raw)} documents\")\n",
    "print(f\"Testing set size: {len(X_test_raw)} documents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f516d252",
   "metadata": {},
   "source": [
    "# 2. Logistic Regression Implementation from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7c6b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import re\n",
    "import string\n",
    "\n",
    "def handle_negations(words):\n",
    "    \"\"\"\n",
    "    Finds negation words and prefixes the following word with 'not_'.\n",
    "    \"\"\"\n",
    "    negation_words = {\"not\", \"no\", \"n't\", \"never\"}\n",
    "    processed_words = []\n",
    "    i = 0\n",
    "    while i < len(words):\n",
    "        word = words[i]\n",
    "        if word in negation_words or re.search(r'\\w+n\\'t$', word):\n",
    "            if i + 1 < len(words):\n",
    "                processed_words.append('not_' + words[i+1])\n",
    "                i += 2\n",
    "            else:\n",
    "                processed_words.append(word)\n",
    "                i += 1\n",
    "        else:\n",
    "            processed_words.append(word)\n",
    "            i += 1\n",
    "    return processed_words\n",
    "\n",
    "def custom_tfidf_vectorizer(tweets):\n",
    "    \"\"\"\n",
    "    Converts a list of text documents to a TF-IDF matrix with negation handling.\n",
    "    \"\"\"\n",
    "    # 1. Build vocabulary and get term frequencies\n",
    "    vocabulary = {}\n",
    "    doc_word_counts = []\n",
    "    punctuation_to_remove = string.punctuation.replace(\"'\", \"\")\n",
    "    for tweet in tweets:\n",
    "        processed_text = tweet.lower().translate(str.maketrans('', '', punctuation_to_remove))\n",
    "        words = handle_negations(processed_text.split())\n",
    "        doc_counts = {}\n",
    "        for word in words:\n",
    "            if word not in vocabulary:\n",
    "                vocabulary[word] = len(vocabulary)\n",
    "            doc_counts[word] = doc_counts.get(word, 0) + 1\n",
    "        doc_word_counts.append(doc_counts)\n",
    "\n",
    "    # 2. Calculate Inverse Document Frequency (IDF)\n",
    "    num_documents = len(tweets)\n",
    "    idf = {}\n",
    "    for word, idx in vocabulary.items():\n",
    "        doc_count = sum(1 for doc in doc_word_counts if word in doc)\n",
    "        # Use a smoothed version to avoid division by zero\n",
    "        idf[word] = np.log((1 + num_documents) / (1 + doc_count)) + 1\n",
    "\n",
    "    # 3. Create TF-IDF feature matrix\n",
    "    X = np.zeros((num_documents, len(vocabulary)))\n",
    "    for i, doc_counts in enumerate(doc_word_counts):\n",
    "        for word, count in doc_counts.items():\n",
    "            tf = count / sum(doc_counts.values())\n",
    "            tfidf = tf * idf[word]\n",
    "            X[i, vocabulary[word]] = tfidf\n",
    "\n",
    "    return X, vocabulary, idf\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def train_logistic_regression(X, y, learning_rate=0.1, n_iterations=1000):\n",
    "    n_samples, n_features = X.shape\n",
    "    w = np.zeros(n_features)\n",
    "    b = 0\n",
    "\n",
    "    # Gradient descent\n",
    "    for i in range(n_iterations):\n",
    "        # Calculate linear model and predictions\n",
    "        linear_model = np.dot(X, w) + b\n",
    "        y_predicted = sigmoid(linear_model)\n",
    "\n",
    "        # Compute gradients\n",
    "        dw = (1 / n_samples) * np.dot(X.T, (y_predicted - y))\n",
    "        db = (1 / n_samples) * np.sum(y_predicted - y)\n",
    "\n",
    "        # Update parameters\n",
    "        w -= learning_rate * dw\n",
    "        b -= learning_rate * db\n",
    "\n",
    "        # Calculate and display the loss every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            # Binary Cross-Entropy (Logistic) Loss\n",
    "            loss = -np.mean(y * np.log(y_predicted) + (1 - y) * np.log(1 - y_predicted))\n",
    "            print(f\"Iteration {i}/{n_iterations}, Loss: {loss:.4f}\")\n",
    "    \n",
    "    return w, b\n",
    "\n",
    "def predict_logistic_regression(X, w, b):\n",
    "    linear_model = np.dot(X, w) + b\n",
    "    y_predicted = sigmoid(linear_model)\n",
    "    y_predicted_cls = [1 if i > 0.5 else 0 for i in y_predicted]\n",
    "    return np.array(y_predicted_cls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c6b542",
   "metadata": {},
   "source": [
    "# 3. Data Transformation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6140d3e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution before oversampling: Counter({np.int64(1): 3303, np.int64(0): 2249})\n",
      "Class distribution after oversampling: Counter({np.int64(0): 3303, np.int64(1): 3303})\n",
      "Training data shape after oversampling: (6606, 1016)\n",
      "Testing data shape: (1388, 1016)\n",
      "\n",
      "Starting model training...\n",
      "Iteration 0/1000, Loss: 0.6931\n",
      "Iteration 100/1000, Loss: 0.5607\n",
      "Iteration 200/1000, Loss: 0.4711\n",
      "Iteration 300/1000, Loss: 0.4077\n",
      "Iteration 400/1000, Loss: 0.3607\n",
      "Iteration 500/1000, Loss: 0.3245\n",
      "Iteration 600/1000, Loss: 0.2958\n",
      "Iteration 700/1000, Loss: 0.2723\n",
      "Iteration 800/1000, Loss: 0.2529\n",
      "Iteration 900/1000, Loss: 0.2364\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Convert string labels to numerical (0 for not_offensive, 1 for offensive)\n",
    "y_train = np.array([1 if c.strip() == 'offensive' else 0 for c in y_train_str])\n",
    "y_test = np.array([1 if c.strip() == 'offensive' else 0 for c in y_test_str])\n",
    "\n",
    "# Preprocess and vectorize text data using TF-IDF\n",
    "X_train, vocabulary, idf_scores = custom_tfidf_vectorizer(X_train_raw)\n",
    "\n",
    "# Handle class imbalance with oversampling\n",
    "from collections import Counter\n",
    "\n",
    "def oversample(X, y):\n",
    "    \"\"\"\n",
    "    A simple random oversampling implementation for imbalanced classes.\n",
    "    It duplicates samples from the minority class to match the majority class size.\n",
    "    \"\"\"\n",
    "    counts = Counter(y)\n",
    "    minority_class = min(counts, key=counts.get)\n",
    "    majority_class = max(counts, key=counts.get)\n",
    "    \n",
    "    minority_indices = np.where(y == minority_class)[0]\n",
    "    majority_indices = np.where(y == majority_class)[0]\n",
    "    \n",
    "    num_minority_samples = len(minority_indices)\n",
    "    num_majority_samples = len(majority_indices)\n",
    "    \n",
    "    # Calculate how many samples to add to the minority class\n",
    "    num_to_add = num_majority_samples - num_minority_samples\n",
    "    \n",
    "    # Randomly select samples from the minority class to duplicate\n",
    "    resample_indices = np.random.choice(minority_indices, size=num_to_add, replace=True)\n",
    "    \n",
    "    # Create the resampled feature matrix and labels\n",
    "    X_resampled = np.vstack([X, X[resample_indices]])\n",
    "    y_resampled = np.concatenate([y, y[resample_indices]])\n",
    "    \n",
    "    # Shuffle the resampled data to mix the classes\n",
    "    shuffler = np.random.permutation(len(y_resampled))\n",
    "    X_resampled = X_resampled[shuffler]\n",
    "    y_resampled = y_resampled[shuffler]\n",
    "    \n",
    "    return X_resampled, y_resampled\n",
    "\n",
    "X_train_resampled, y_train_resampled = oversample(X_train, y_train)\n",
    "\n",
    "print(\"Class distribution before oversampling:\", Counter(y_train))\n",
    "print(\"Class distribution after oversampling:\", Counter(y_train_resampled))\n",
    "\n",
    "# Ensure test data has the same features and TF-IDF scores as training data\n",
    "def map_test_to_tfidf(test_raw, vocab, idf_scores):\n",
    "    X = np.zeros((len(test_raw), len(vocab)))\n",
    "    punctuation_to_remove = string.punctuation.replace(\"'\", \"\")\n",
    "    for i, tweet in enumerate(test_raw):\n",
    "        processed_text = tweet.lower().translate(str.maketrans('', '', punctuation_to_remove))\n",
    "        words = handle_negations(processed_text.split())\n",
    "        doc_word_counts = {}\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                doc_word_counts[word] = doc_word_counts.get(word, 0) + 1\n",
    "        \n",
    "        if sum(doc_word_counts.values()) > 0:\n",
    "            for word, count in doc_word_counts.items():\n",
    "                tf = count / sum(doc_word_counts.values())\n",
    "                tfidf = tf * idf_scores.get(word, 0)\n",
    "                X[i, vocab[word]] = tfidf\n",
    "    return X\n",
    "\n",
    "X_test = map_test_to_tfidf(X_test_raw, vocabulary, idf_scores)\n",
    "\n",
    "print(f\"Training data shape after oversampling: {X_train_resampled.shape}\")\n",
    "print(f\"Testing data shape: {X_test.shape}\")\n",
    "\n",
    "# Train the Logistic Regression model on the resampled data and get weights/bias\n",
    "print(\"\\nStarting model training...\")\n",
    "weights, bias = train_logistic_regression(X_train_resampled, y_train_resampled, learning_rate=0.1, n_iterations=1000)\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31af5002",
   "metadata": {},
   "source": [
    "# 4. Prediction and Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "52c0aa43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the custom Logistic Regression model: 0.98\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def accuracy_score(y_true, y_pred):\n",
    "    \"\"\"Calculates the accuracy of the predictions.\"\"\"\n",
    "    return np.sum(y_true == y_pred) / len(y_true)\n",
    "\n",
    "# Make predictions on the test set using the trained weights and bias\n",
    "y_pred = predict_logistic_regression(X_test, weights, bias)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy of the custom Logistic Regression model: {accuracy:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8a059b0",
   "metadata": {},
   "source": [
    "## 5. Saving and Loading the Model Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3ae7fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model parameters saved to logistic_regression.pkl\n",
      "Model parameters loaded from logistic_regression_tfidf.pkl\n",
      "\n",
      "Loaded weights shape: (1016,)\n",
      "Loaded bias: -0.13166330297141485\n",
      "Loaded vocabulary size: 1016\n",
      "Loaded IDF scores size: 1016\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model_params(weights, bias, vocabulary, idf_scores, filename='logistic_regression_tfidf.pkl'):\n",
    "    \"\"\"Save the trained model parameters and TF-IDF data to a file.\"\"\"\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump({\n",
    "            'weights': weights,\n",
    "            'bias': bias,\n",
    "            'vocabulary': vocabulary,\n",
    "            'idf_scores': idf_scores\n",
    "        }, f)\n",
    "    print(f'Model parameters saved to {filename}')\n",
    "\n",
    "def load_model_params(filename='logistic_regression_tfidf.pkl'):\n",
    "    \"\"\"Load the trained model parameters from a file.\"\"\"\n",
    "    with open(filename, 'rb') as f:\n",
    "        params = pickle.load(f)\n",
    "    print(f'Model parameters loaded from {filename}')\n",
    "    return params['weights'], params['bias'], params['vocabulary'], params['idf_scores']\n",
    "\n",
    "# Save the weights, bias, vocabulary, and idf_scores returned from the training function\n",
    "save_model_params(weights, bias, vocabulary, idf_scores)\n",
    "\n",
    "# Load the parameters and print their shapes to verify\n",
    "weights, bias, loaded_vocab, loaded_idf = load_model_params()\n",
    "print(\"\\nLoaded weights shape:\", weights.shape)\n",
    "print(\"Loaded bias:\", bias)\n",
    "print(\"Loaded vocabulary size:\", len(loaded_vocab))\n",
    "print(\"Loaded IDF scores size:\", len(loaded_idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3db97df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9820\n",
      "\n",
      "Classification Report:\n",
      "Category         Precision    Recall  F1-Score   Support\n",
      "--------------------------------------------------------\n",
      "not_offensive           0.98      0.97      0.98       578\n",
      "offensive               0.98      0.99      0.98       810\n",
      "--------------------------------------------------------\n",
      "Macro Average         0.98      0.98      0.98      1388\n"
     ]
    }
   ],
   "source": [
    "def classification_report_manual(y_true, y_pred, target_names):\n",
    "    report = []\n",
    "    for i, label in enumerate(target_names):\n",
    "        tp = np.sum((y_true == i) & (y_pred == i))\n",
    "        fp = np.sum((y_true != i) & (y_pred == i))\n",
    "        fn = np.sum((y_true == i) & (y_pred != i))\n",
    "        support = np.sum(y_true == i)\n",
    "        precision = tp / (tp + fp) if (tp + fp) > 0 else 0.0\n",
    "        recall = tp / (tp + fn) if (tp + fn) > 0 else 0.0\n",
    "        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0.0\n",
    "        report.append((label, precision, recall, f1, support))\n",
    "    # Macro average\n",
    "    macro_precision = np.mean([r[1] for r in report])\n",
    "    macro_recall = np.mean([r[2] for r in report])\n",
    "    macro_f1 = np.mean([r[3] for r in report])\n",
    "    macro_support = np.sum([r[4] for r in report])\n",
    "    # Compute accuracy for this report\n",
    "    accuracy = np.sum(y_true == y_pred) / len(y_true)\n",
    "    print(f\"Overall Accuracy: {accuracy:.4f}\\n\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(\"Category         Precision    Recall  F1-Score   Support\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    for row in report:\n",
    "        print(f\"{row[0]:<18} {row[1]:>9.2f} {row[2]:>9.2f} {row[3]:>9.2f} {row[4]:>9}\")\n",
    "    print(\"--------------------------------------------------------\")\n",
    "    print(f\"Macro Average    {macro_precision:>9.2f} {macro_recall:>9.2f} {macro_f1:>9.2f} {macro_support:>9}\")\n",
    "\n",
    "\n",
    "target_names = ['not_offensive', 'offensive']\n",
    "classification_report_manual(y_test, y_pred, target_names)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
